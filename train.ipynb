{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "import random\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm_notebook, trange\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "from pytorch_transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer,\n",
    "                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n",
    "                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n",
    "                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
    "\n",
    "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
    "\n",
    "from utils import (convert_examples_to_features,\n",
    "                        output_modes, processors)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data_dir': 'data/',\n",
    "    'model_type':  'xlnet',\n",
    "    'model_name': 'xlnet-base-cased',\n",
    "    'task_name': 'binary',\n",
    "    'output_dir': 'outputs/',\n",
    "    'cache_dir': 'cache/',\n",
    "    'do_train': True,\n",
    "    'do_eval': True,\n",
    "    'fp16': True,\n",
    "    'fp16_opt_level': 'O1',\n",
    "    'max_seq_length': 128,\n",
    "    'output_mode': 'classification',\n",
    "    'train_batch_size': 8,\n",
    "    'eval_batch_size': 8,\n",
    "\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'num_train_epochs': 5,\n",
    "    'weight_decay': 0,\n",
    "    'learning_rate': 4e-5,\n",
    "    'adam_epsilon': 1e-8,\n",
    "    'warmup_steps': 0,\n",
    "    'max_grad_norm': 1.0,\n",
    "\n",
    "    'logging_steps': 50,\n",
    "    'evaluate_during_training': False,\n",
    "    'save_steps': 2000,\n",
    "    'eval_all_checkpoints': True,\n",
    "\n",
    "    'overwrite_output_dir': True,\n",
    "    'reprocess_input_data': True,\n",
    "    'notes': 'Using Yelp Reviews dataset'\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adam_epsilon': 1e-08,\n",
       " 'cache_dir': 'cache/',\n",
       " 'data_dir': 'data/',\n",
       " 'do_eval': True,\n",
       " 'do_train': True,\n",
       " 'eval_all_checkpoints': True,\n",
       " 'eval_batch_size': 8,\n",
       " 'evaluate_during_training': False,\n",
       " 'fp16': True,\n",
       " 'fp16_opt_level': 'O1',\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'learning_rate': 4e-05,\n",
       " 'logging_steps': 50,\n",
       " 'max_grad_norm': 1.0,\n",
       " 'max_seq_length': 128,\n",
       " 'model_name': 'xlnet-base-cased',\n",
       " 'model_type': 'xlnet',\n",
       " 'notes': 'Using Yelp Reviews dataset',\n",
       " 'num_train_epochs': 5,\n",
       " 'output_dir': 'outputs/',\n",
       " 'output_mode': 'classification',\n",
       " 'overwrite_output_dir': True,\n",
       " 'reprocess_input_data': True,\n",
       " 'save_steps': 2000,\n",
       " 'task_name': 'binary',\n",
       " 'train_batch_size': 8,\n",
       " 'warmup_steps': 0,\n",
       " 'weight_decay': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('args.json', 'w') as f:\n",
    "    json.dump(args, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(args['output_dir']) and os.listdir(args['output_dir']) and args['do_train'] and not args['overwrite_output_dir']:\n",
    "    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args['output_dir']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer),\n",
    "    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n",
    "    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
    "    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
    "}\n",
    "\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args['model_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /u/spa-d2/grad/mna245/.cache/torch/pytorch_transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.ef1824921bc0786e97dc88d55eb17aabf18aac90f24bd34c0650529e7ba27d6f\n",
      "INFO:pytorch_transformers.modeling_utils:Model config {\n",
      "  \"attn_type\": \"bi\",\n",
      "  \"bi_data\": false,\n",
      "  \"clamp_len\": -1,\n",
      "  \"d_head\": 64,\n",
      "  \"d_inner\": 3072,\n",
      "  \"d_model\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"end_n_top\": 5,\n",
      "  \"ff_activation\": \"gelu\",\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mem_len\": null,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_token\": 32000,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"reuse_len\": null,\n",
      "  \"same_length\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": \"tanh\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"last\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"untie_r\": true\n",
      "}\n",
      "\n",
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /u/spa-d2/grad/mna245/.cache/torch/pytorch_transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(args['model_name'], num_labels=2, finetuning_task=args['task_name'])\n",
    "tokenizer = tokenizer_class.from_pretrained(args['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /u/spa-d2/grad/mna245/.cache/torch/pytorch_transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.ef1824921bc0786e97dc88d55eb17aabf18aac90f24bd34c0650529e7ba27d6f\n",
      "INFO:pytorch_transformers.modeling_utils:Model config {\n",
      "  \"attn_type\": \"bi\",\n",
      "  \"bi_data\": false,\n",
      "  \"clamp_len\": -1,\n",
      "  \"d_head\": 64,\n",
      "  \"d_inner\": 3072,\n",
      "  \"d_model\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"end_n_top\": 5,\n",
      "  \"ff_activation\": \"gelu\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mem_len\": null,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_token\": 32000,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"reuse_len\": null,\n",
      "  \"same_length\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": \"tanh\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"last\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"untie_r\": true\n",
      "}\n",
      "\n",
      "INFO:pytorch_transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /u/spa-d2/grad/mna245/.cache/torch/pytorch_transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac\n",
      "INFO:pytorch_transformers.modeling_utils:Weights of XLNetForSequenceClassification not initialized from pretrained model: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "INFO:pytorch_transformers.modeling_utils:Weights from pretrained model not used in XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n"
     ]
    }
   ],
   "source": [
    "model = model_class.from_pretrained(args['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = args['task_name']\n",
    "\n",
    "processor = processors[task]()\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(task, tokenizer, evaluate=False):\n",
    "    processor = processors[task]()\n",
    "    output_mode = args['output_mode']\n",
    "    \n",
    "    mode = 'dev' if evaluate else 'train'\n",
    "    cached_features_file = os.path.join(args['data_dir'], f\"cached_{mode}_{args['model_name']}_{args['max_seq_length']}_{task}\")\n",
    "    \n",
    "    if os.path.exists(cached_features_file) and not args['reprocess_input_data']:\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "               \n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", args['data_dir'])\n",
    "        label_list = processor.get_labels()\n",
    "        examples = processor.get_dev_examples(args['data_dir']) if evaluate else processor.get_train_examples(args['data_dir'])\n",
    "        \n",
    "        features = convert_examples_to_features(examples, label_list, args['max_seq_length'], tokenizer, output_mode,\n",
    "            cls_token_at_end=bool(args['model_type'] in ['xlnet']),            # xlnet has a cls token at the end\n",
    "            cls_token=tokenizer.cls_token,\n",
    "            sep_token=tokenizer.sep_token,\n",
    "            cls_token_segment_id=2 if args['model_type'] in ['xlnet'] else 0,\n",
    "            pad_on_left=bool(args['model_type'] in ['xlnet']),                 # pad on the left for xlnet\n",
    "            pad_token_segment_id=4 if args['model_type'] in ['xlnet'] else 0)\n",
    "        \n",
    "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "        torch.save(features, cached_features_file)\n",
    "        \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    if output_mode == \"classification\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    elif output_mode == \"regression\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, model, tokenizer):\n",
    "    tb_writer = SummaryWriter()\n",
    "    \n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args['train_batch_size'])\n",
    "    \n",
    "    t_total = len(train_dataloader) // args['gradient_accumulation_steps'] * args['num_train_epochs']\n",
    "    \n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args['weight_decay']},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args['learning_rate'], eps=args['adam_epsilon'])\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args['warmup_steps'], t_total=t_total)\n",
    "    \n",
    "    if args['fp16']:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args['fp16_opt_level'])\n",
    "        \n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args['num_train_epochs'])\n",
    "    logger.info(\"  Total train batch size  = %d\", args['train_batch_size'])\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args['gradient_accumulation_steps'])\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(args['num_train_epochs']), desc=\"Epoch\")\n",
    "    \n",
    "    n_it = 0\n",
    "    for _ in train_iterator:\n",
    "        n_it +=1\n",
    "        print(\"n_it: \",n_it)\n",
    "        #if n_it >=3:\n",
    "        #    args['gradient_accumulation_steps'] +=1\n",
    "        epoch_iterator = tqdm_notebook(train_dataloader, desc=\"Iteration\")\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "                      'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
    "            print(\"\\r%f\" % loss, end='')\n",
    "\n",
    "            if args['gradient_accumulation_steps'] > 1:\n",
    "                loss = loss / args['gradient_accumulation_steps']\n",
    "\n",
    "            if args['fp16']:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args['max_grad_norm'])\n",
    "                \n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args['max_grad_norm'])\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if args['logging_steps'] > 0 and global_step % args['logging_steps'] == 0:\n",
    "                    # Log metrics\n",
    "                    if args['evaluate_during_training']:  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                        results = evaluate(model, tokenizer)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar('eval_{}'.format(key), value, global_step)\n",
    "                    tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar('loss', (tr_loss - logging_loss)/args['logging_steps'], global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if args['save_steps'] > 0 and global_step % args['save_steps'] == 0:\n",
    "                    # Save model checkpoint\n",
    "                    output_dir = os.path.join(args['output_dir'], 'checkpoint-{}'.format(global_step))\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "                    model_to_save.save_pretrained(output_dir)\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, matthews_corrcoef, confusion_matrix\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def get_mismatched(labels, preds):\n",
    "    mismatched = labels != preds\n",
    "    examples = processor.get_dev_examples(args['data_dir'])\n",
    "    wrong = [i for (i, v) in zip(examples, mismatched) if v]\n",
    "    \n",
    "    return wrong\n",
    "\n",
    "def get_eval_report(labels, preds):\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    return {\n",
    "        \"mcc\": mcc,\n",
    "        \"tp\": tp,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn\n",
    "    }, get_mismatched(labels, preds)\n",
    "\n",
    "def compute_metrics(task_name, preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return get_eval_report(labels, preds)\n",
    "\n",
    "def evaluate(model, tokenizer, prefix=\"\"):\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_output_dir = args['output_dir']\n",
    "\n",
    "    results = {}\n",
    "    EVAL_TASK = args['task_name']\n",
    "\n",
    "    eval_dataset = load_and_cache_examples(EVAL_TASK, tokenizer, evaluate=True)\n",
    "    if not os.path.exists(eval_output_dir):\n",
    "        os.makedirs(eval_output_dir)\n",
    "\n",
    "\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "                      'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            print(outputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    if args['output_mode'] == \"classification\":\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "    elif args['output_mode'] == \"regression\":\n",
    "        preds = np.squeeze(preds)\n",
    "    result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n",
    "    results.update(result)\n",
    "\n",
    "    output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return results, wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|██████████| 700/700 [00:23<00:00, 29.20it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_train_bert-base-uncased_128_binary\n",
      "INFO:__main__:***** Running training *****\n",
      "INFO:__main__:  Num examples = 700\n",
      "INFO:__main__:  Num Epochs = 5\n",
      "INFO:__main__:  Total train batch size  = 8\n",
      "INFO:__main__:  Gradient Accumulation steps = 1\n",
      "INFO:__main__:  Total optimization steps = 440\n",
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "n_it:  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbe7f19bedc44dfbebf2f967c33e71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=88, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.736769"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/spa-d2/grad/mna245/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:73: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675974Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "0.779984Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "0.429582Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "0.665977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 1/5 [00:15<01:02, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.206784\n",
      "n_it:  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7ed6be4a854648a7f52f0cebb7b3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=88, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.106833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 2/5 [00:31<00:46, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_it:  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b53756979364efba871dfa729063dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=88, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.605805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 3/5 [00:46<00:31, 15.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.005388\n",
      "n_it:  4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d91c3a2313242848c8e603b6eb2f8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=88, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 4/5 [01:01<00:15, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_it:  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ec9e62831544eba560e696fe366533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=88, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [01:16<00:00, 15.34s/it]\n",
      "INFO:__main__: global_step = 440, average loss = 0.23126339555125344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if args['do_train']:\n",
    "    train_dataset = load_and_cache_examples(task, tokenizer)\n",
    "    global_step, tr_loss = train(train_dataset, model, tokenizer)\n",
    "    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saving model checkpoint to outputs/\n"
     ]
    }
   ],
   "source": [
    "if args['do_train']:\n",
    "    if not os.path.exists(args['output_dir']):\n",
    "            os.makedirs(args['output_dir'])\n",
    "    logger.info(\"Saving model checkpoint to %s\", args['output_dir'])\n",
    "    \n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "    model_to_save.save_pretrained(args['output_dir'])\n",
    "    tokenizer.save_pretrained(args['output_dir'])\n",
    "    torch.save(args, os.path.join(args['output_dir'], 'training_args.bin'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Evaluate the following checkpoints: ['outputs']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Creating features from dataset file at data/\n",
      "100%|██████████| 687/687 [00:12<00:00, 54.22it/s]\n",
      "INFO:__main__:Saving features into cached file data/cached_dev_xlnet-base-cased_128_binary\n",
      "INFO:__main__:***** Running evaluation  *****\n",
      "INFO:__main__:  Num examples = 687\n",
      "INFO:__main__:  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026a3b2f6b0941fbbc139262b130c420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=86, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(2.0272, device='cuda:0'), tensor([[ 0.6726, -0.7952],\n",
      "        [-3.5099,  3.6768],\n",
      "        [-3.5650,  3.7450],\n",
      "        [ 0.5165, -1.3429],\n",
      "        [-3.2236,  3.8345],\n",
      "        [ 3.2463, -3.6369],\n",
      "        [ 1.8986, -2.7977],\n",
      "        [-3.2999,  3.7743]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.9375, device='cuda:0'), tensor([[-3.2762,  3.9448],\n",
      "        [-3.1806,  3.8222],\n",
      "        [-3.5450,  3.9464],\n",
      "        [ 2.6947, -3.1245],\n",
      "        [-3.2391,  3.8407],\n",
      "        [-3.2741,  3.6918],\n",
      "        [-3.4677,  3.5930],\n",
      "        [-3.3419,  3.7866]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.6843, device='cuda:0'), tensor([[-3.0387,  3.7219],\n",
      "        [-2.8399,  3.4074],\n",
      "        [ 2.9887, -3.5995],\n",
      "        [-3.2544,  3.9010],\n",
      "        [-2.9703,  3.7595],\n",
      "        [-3.3960,  3.8441],\n",
      "        [-3.2688,  3.8003],\n",
      "        [-3.3119,  3.9063]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.5210, device='cuda:0'), tensor([[-3.2760,  3.8365],\n",
      "        [-3.2784,  3.6238],\n",
      "        [-3.2098,  3.8567],\n",
      "        [-3.5014,  3.8029],\n",
      "        [-3.2717,  3.8351],\n",
      "        [-3.0947,  3.8025],\n",
      "        [ 2.8194, -3.4751],\n",
      "        [-2.2262,  2.8160]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.0292, device='cuda:0'), tensor([[-3.3461,  3.8661],\n",
      "        [ 2.8626, -3.2331],\n",
      "        [ 1.1725, -1.2028],\n",
      "        [ 0.9283, -1.0327],\n",
      "        [ 2.9214, -3.7064],\n",
      "        [-3.1369,  3.6224],\n",
      "        [-3.3198,  3.9013],\n",
      "        [ 2.1560, -2.8806]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.6591, device='cuda:0'), tensor([[-1.8314,  2.8784],\n",
      "        [-3.0474,  3.6471],\n",
      "        [-3.4303,  3.7902],\n",
      "        [-3.0669,  3.6976],\n",
      "        [-3.0499,  3.7808],\n",
      "        [-3.2399,  3.8584],\n",
      "        [-0.6884,  0.9109],\n",
      "        [-3.4244,  3.6492]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.0911, device='cuda:0'), tensor([[ 3.2856, -3.9029],\n",
      "        [-2.8237,  3.6299],\n",
      "        [-3.0390,  3.6576],\n",
      "        [ 2.9130, -2.8782],\n",
      "        [-1.4418,  2.0964],\n",
      "        [-3.2186,  3.7212],\n",
      "        [ 3.0167, -2.7076],\n",
      "        [-3.1131,  3.7219]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.8419, device='cuda:0'), tensor([[-3.5220,  3.7963],\n",
      "        [ 2.2609, -2.8815],\n",
      "        [-3.2578,  3.5506],\n",
      "        [-3.0825,  3.7588],\n",
      "        [-3.3799,  3.7048],\n",
      "        [-3.2716,  3.7048],\n",
      "        [-3.5047,  3.9008],\n",
      "        [-3.5155,  3.8568]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.2490, device='cuda:0'), tensor([[-1.3784,  1.4345],\n",
      "        [ 2.9584, -3.2270],\n",
      "        [-3.2116,  3.8747],\n",
      "        [ 2.0574, -1.5356],\n",
      "        [-3.2431,  3.6757],\n",
      "        [-3.3210,  3.6408],\n",
      "        [-2.9785,  3.7679],\n",
      "        [ 2.8102, -3.6578]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.6193, device='cuda:0'), tensor([[-3.1063,  3.9714],\n",
      "        [ 2.8107, -3.4957],\n",
      "        [-3.1329,  3.7340],\n",
      "        [-3.2541,  3.8580],\n",
      "        [-2.2775,  3.4314],\n",
      "        [-2.5109,  2.8682],\n",
      "        [-3.3082,  3.9154],\n",
      "        [ 2.2707, -2.4864]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(3.0328, device='cuda:0'), tensor([[-3.1701,  3.7329],\n",
      "        [-2.7523,  3.5415],\n",
      "        [-3.2229,  3.8564],\n",
      "        [-3.2356,  3.9594],\n",
      "        [-1.8463,  2.2327],\n",
      "        [ 1.8890, -2.5121],\n",
      "        [-3.3026,  3.8036],\n",
      "        [-3.1379,  3.8136]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.9056, device='cuda:0'), tensor([[-3.3642,  3.6910],\n",
      "        [-2.9097,  3.4050],\n",
      "        [ 2.6731, -3.2725],\n",
      "        [-3.5061,  3.7818],\n",
      "        [ 3.1541, -3.1771],\n",
      "        [-3.3509,  3.8836],\n",
      "        [-3.2661,  3.8600],\n",
      "        [-3.1868,  3.8130]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.5720, device='cuda:0'), tensor([[-3.1530,  3.7025],\n",
      "        [ 2.9144, -2.9257],\n",
      "        [-3.2025,  3.7984],\n",
      "        [-3.2076,  3.8845],\n",
      "        [-3.6100,  3.6337],\n",
      "        [ 3.0103, -3.5909],\n",
      "        [-2.7055,  3.5244],\n",
      "        [-3.2966,  3.7543]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(3.1963, device='cuda:0'), tensor([[-3.3536,  3.7830],\n",
      "        [ 1.7488, -2.2748],\n",
      "        [-3.2789,  3.8679],\n",
      "        [-3.2429,  3.9029],\n",
      "        [ 3.0141, -3.8118],\n",
      "        [-1.7086,  2.5208],\n",
      "        [ 3.3791, -3.8328],\n",
      "        [-3.3016,  4.0305]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.7167, device='cuda:0'), tensor([[-2.9581,  3.9030],\n",
      "        [-3.1464,  3.7537],\n",
      "        [-2.5193,  3.1956],\n",
      "        [-1.9419,  2.6221],\n",
      "        [-2.9421,  3.7502],\n",
      "        [-3.5966,  3.7717],\n",
      "        [-3.5566,  3.8379],\n",
      "        [-3.2816,  3.8780]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.0013, device='cuda:0'), tensor([[-2.5590,  3.4926],\n",
      "        [-3.1927,  3.7029],\n",
      "        [ 2.9499, -3.8467],\n",
      "        [-3.2694,  3.8450],\n",
      "        [-3.5301,  3.7577],\n",
      "        [ 3.2589, -3.8106],\n",
      "        [-2.9535,  3.5823],\n",
      "        [-2.6650,  3.5259]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.0016, device='cuda:0'), tensor([[-3.1465,  3.9972],\n",
      "        [-3.2421,  3.8699],\n",
      "        [ 2.6770, -2.4450],\n",
      "        [-3.1575,  3.5037],\n",
      "        [-3.1283,  3.9456],\n",
      "        [-3.4621,  3.8703],\n",
      "        [-3.1575,  3.5037],\n",
      "        [-3.0558,  3.6286]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.8783, device='cuda:0'), tensor([[-3.2811,  3.8845],\n",
      "        [-3.4496,  3.6973],\n",
      "        [-3.2183,  3.8381],\n",
      "        [-3.2077,  3.7323],\n",
      "        [-3.2530,  3.6705],\n",
      "        [-0.1004,  0.0380],\n",
      "        [-3.4354,  3.6541],\n",
      "        [ 2.9656, -3.5522]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.5193, device='cuda:0'), tensor([[ 2.1358, -3.4585],\n",
      "        [-3.1970,  3.7395],\n",
      "        [ 0.5161, -1.2220],\n",
      "        [ 3.2049, -3.9320],\n",
      "        [-3.4653,  3.9412],\n",
      "        [-2.2515,  2.7863],\n",
      "        [ 2.8522, -3.5239],\n",
      "        [-2.3548,  3.1901]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.4309, device='cuda:0'), tensor([[-3.1860,  3.9165],\n",
      "        [-2.4246,  2.7184],\n",
      "        [-3.2585,  3.8999],\n",
      "        [-3.3870,  3.6824],\n",
      "        [-3.4497,  3.8475],\n",
      "        [-3.0093,  3.5323],\n",
      "        [ 2.6191, -3.3863],\n",
      "        [-3.2871,  3.9012]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.8697, device='cuda:0'), tensor([[-3.1414,  3.8054],\n",
      "        [-2.9872,  3.5199],\n",
      "        [-3.3348,  3.7743],\n",
      "        [-3.2140,  3.9788],\n",
      "        [-3.0585,  3.8907],\n",
      "        [ 2.8789, -3.5839],\n",
      "        [-3.1881,  3.6982],\n",
      "        [-3.2464,  3.7885]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.9211, device='cuda:0'), tensor([[ 2.5696, -2.5613],\n",
      "        [-3.2701,  3.6569],\n",
      "        [-2.9671,  3.7037],\n",
      "        [-3.4698,  3.8857],\n",
      "        [ 2.7578, -3.5916],\n",
      "        [-3.2889,  3.7045],\n",
      "        [-3.1530,  3.8970],\n",
      "        [-3.0336,  3.7120]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.5478, device='cuda:0'), tensor([[-3.4416,  3.8090],\n",
      "        [-2.4971,  3.2289],\n",
      "        [-3.4280,  3.9962],\n",
      "        [-3.4030,  3.8534],\n",
      "        [-3.3771,  3.8019],\n",
      "        [ 2.1117, -3.0783],\n",
      "        [-3.4523,  3.9347],\n",
      "        [-3.3308,  3.8391]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(3.0504, device='cuda:0'), tensor([[-3.2113,  3.6438],\n",
      "        [ 2.9624, -3.6690],\n",
      "        [-3.1714,  3.7831],\n",
      "        [-2.2159,  2.8091],\n",
      "        [-3.1562,  3.7929],\n",
      "        [-2.3577,  3.1995],\n",
      "        [-3.0638,  3.8790],\n",
      "        [-3.0469,  3.7137]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.8573, device='cuda:0'), tensor([[-3.2951,  3.7021],\n",
      "        [-3.0328,  3.8113],\n",
      "        [-3.1403,  3.7629],\n",
      "        [-3.2839,  3.8572],\n",
      "        [ 2.4067, -2.6287],\n",
      "        [-3.0964,  3.8878],\n",
      "        [-3.1460,  3.6617],\n",
      "        [ 2.7966, -3.5356]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(2.1126, device='cuda:0'), tensor([[-3.2434,  3.9056],\n",
      "        [-2.7075,  3.6450],\n",
      "        [-3.2374,  3.9146],\n",
      "        [-2.5663,  3.4737],\n",
      "        [-1.9774,  2.3366],\n",
      "        [ 1.9991, -2.6997],\n",
      "        [-2.8803,  3.6360],\n",
      "        [ 3.0822, -3.7976]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.7364, device='cuda:0'), tensor([[-3.1427,  3.5045],\n",
      "        [-3.1724,  3.8813],\n",
      "        [ 3.2472, -3.7344],\n",
      "        [-3.2526,  3.8011],\n",
      "        [-3.3526,  3.7659],\n",
      "        [-3.3639,  3.7602],\n",
      "        [-3.2776,  3.9566],\n",
      "        [-3.1323,  3.6271]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.5762, device='cuda:0'), tensor([[-2.9317,  3.6909],\n",
      "        [-3.2520,  3.8781],\n",
      "        [-3.3220,  3.8885],\n",
      "        [-3.2123,  3.8104],\n",
      "        [ 3.2182, -3.4815],\n",
      "        [ 2.3027, -2.9774],\n",
      "        [ 3.3171, -3.8244],\n",
      "        [-3.1677,  3.7851]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.7871, device='cuda:0'), tensor([[ 0.2662,  0.4093],\n",
      "        [-3.2513,  3.8902],\n",
      "        [-3.2663,  3.7799],\n",
      "        [-3.1607,  3.8782],\n",
      "        [-3.5467,  3.7893],\n",
      "        [ 2.4999, -2.4090],\n",
      "        [-3.4322,  3.8197],\n",
      "        [-2.9480,  3.4574]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.0227, device='cuda:0'), tensor([[ 3.1407, -3.8198],\n",
      "        [-3.1834,  3.8211],\n",
      "        [ 2.5497, -2.9533],\n",
      "        [ 3.5066, -3.8697],\n",
      "        [ 2.3341, -3.2778],\n",
      "        [-2.9331,  3.6502],\n",
      "        [-3.3467,  3.9266],\n",
      "        [-0.4354, -0.0634]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.0318, device='cuda:0'), tensor([[-3.3305,  3.8174],\n",
      "        [-3.1910,  3.7709],\n",
      "        [ 2.7034, -3.2631],\n",
      "        [-3.1924,  3.7583],\n",
      "        [-3.4356,  3.9026],\n",
      "        [ 1.7562, -1.7860],\n",
      "        [-3.2807,  3.8815],\n",
      "        [ 0.9837, -0.4212]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.3395, device='cuda:0'), tensor([[-2.8859,  3.6621],\n",
      "        [ 2.7748, -3.5161],\n",
      "        [-3.1769,  3.8151],\n",
      "        [-1.1951,  1.7581],\n",
      "        [-3.1512,  3.5918],\n",
      "        [-3.0920,  3.6869],\n",
      "        [-3.4786,  3.7202],\n",
      "        [-0.7941,  2.0130]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.9348, device='cuda:0'), tensor([[-3.1697,  3.8125],\n",
      "        [ 1.1149, -1.1639],\n",
      "        [-3.2737,  3.8531],\n",
      "        [ 2.4299, -3.2296],\n",
      "        [ 0.4344, -0.4339],\n",
      "        [-3.2684,  3.8000],\n",
      "        [-3.0051,  3.7162],\n",
      "        [-3.0479,  3.8478]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.8084, device='cuda:0'), tensor([[-3.4781,  3.8259],\n",
      "        [-3.0705,  3.6416],\n",
      "        [ 3.0161, -3.5521],\n",
      "        [-3.2363,  3.8969],\n",
      "        [-3.1308,  3.7948],\n",
      "        [-3.0565,  3.5089],\n",
      "        [-3.5380,  3.8435],\n",
      "        [-3.2868,  3.8681]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.9261, device='cuda:0'), tensor([[-2.5178,  3.2672],\n",
      "        [-3.2293,  3.9075],\n",
      "        [-3.2966,  3.7687],\n",
      "        [ 0.7902, -0.1452],\n",
      "        [-3.0778,  3.5279],\n",
      "        [ 1.7367, -1.8852],\n",
      "        [ 3.1053, -3.5151],\n",
      "        [-3.2771,  3.7656]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(3.6167, device='cuda:0'), tensor([[-3.2780,  3.7446],\n",
      "        [-2.9097,  3.4050],\n",
      "        [-3.2272,  3.8509],\n",
      "        [-0.3788,  0.8885],\n",
      "        [ 2.2785, -2.8465],\n",
      "        [-3.3462,  3.7657],\n",
      "        [-2.6634,  3.5289],\n",
      "        [ 3.2778, -3.5453]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.0754, device='cuda:0'), tensor([[ 0.3104,  0.0818],\n",
      "        [ 2.8198, -2.5997],\n",
      "        [-3.3799,  3.6949],\n",
      "        [-3.2431,  3.6757],\n",
      "        [ 3.3499, -3.6255],\n",
      "        [-2.1705,  2.5781],\n",
      "        [-3.2446,  3.8708],\n",
      "        [-3.3660,  3.7799]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.9281, device='cuda:0'), tensor([[-3.3587,  3.7444],\n",
      "        [-3.2490,  3.8650],\n",
      "        [-3.3935,  3.8935],\n",
      "        [-3.2665,  3.6303],\n",
      "        [ 1.5456, -1.4984],\n",
      "        [-3.2292,  3.7494],\n",
      "        [-0.8942,  0.9656],\n",
      "        [-3.6506,  3.8440]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.6625, device='cuda:0'), tensor([[-3.4355,  3.5243],\n",
      "        [-3.3150,  3.9884],\n",
      "        [-3.2722,  3.7591],\n",
      "        [-0.3357,  0.9395],\n",
      "        [-3.4990,  3.8576],\n",
      "        [-3.3526,  3.6682],\n",
      "        [-3.4445,  3.8281],\n",
      "        [-1.9538,  2.5052]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.7146, device='cuda:0'), tensor([[ 2.1770, -3.1760],\n",
      "        [ 3.1593, -3.4211],\n",
      "        [ 2.9253, -3.9024],\n",
      "        [-3.2651,  3.7980],\n",
      "        [-2.9441,  3.3273],\n",
      "        [-3.3230,  3.8298],\n",
      "        [ 1.1948, -1.5583],\n",
      "        [-3.2435,  3.8900]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.7707, device='cuda:0'), tensor([[-3.2096,  3.8415],\n",
      "        [-3.3307,  3.7359],\n",
      "        [-2.7325,  3.3072],\n",
      "        [-3.4281,  3.8341],\n",
      "        [ 2.8285, -3.5126],\n",
      "        [-3.1962,  3.8181],\n",
      "        [-3.3847,  3.7975],\n",
      "        [ 0.1849,  0.4869]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.4123, device='cuda:0'), tensor([[ 0.6968, -1.0535],\n",
      "        [-1.1007,  1.9880],\n",
      "        [-3.2485,  3.8455],\n",
      "        [ 2.9402, -3.8732],\n",
      "        [-3.2856,  3.7561],\n",
      "        [-3.1225,  3.9055],\n",
      "        [-3.4502,  3.7712],\n",
      "        [-3.1459,  3.8383]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.9500, device='cuda:0'), tensor([[ 1.3010, -1.0703],\n",
      "        [-3.0211,  3.6594],\n",
      "        [-3.1839,  3.7818],\n",
      "        [-3.4882,  4.0161],\n",
      "        [-3.5683,  3.8253],\n",
      "        [-3.1093,  3.7170],\n",
      "        [-3.4498,  3.8142],\n",
      "        [-3.1047,  3.8097]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.9318, device='cuda:0'), tensor([[-1.8695,  2.3784],\n",
      "        [-3.5329,  3.7069],\n",
      "        [ 2.5591, -2.5760],\n",
      "        [-3.3523,  3.8600],\n",
      "        [-3.2685,  3.7861],\n",
      "        [-3.3251,  3.9146],\n",
      "        [ 1.1044, -2.0589],\n",
      "        [-3.4108,  3.9784]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.0153, device='cuda:0'), tensor([[-3.2504,  3.8870],\n",
      "        [ 1.3402, -1.4105],\n",
      "        [-3.3774,  3.8636],\n",
      "        [ 3.4195, -3.6478],\n",
      "        [-3.1709,  3.7816],\n",
      "        [-3.2803,  3.7313],\n",
      "        [ 1.4663, -2.2474],\n",
      "        [ 1.4876, -1.9326]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.0094, device='cuda:0'), tensor([[-3.2016,  3.7906],\n",
      "        [-3.4014,  3.7786],\n",
      "        [-3.1761,  3.7847],\n",
      "        [-3.2179,  3.8627],\n",
      "        [-2.9339,  3.5398],\n",
      "        [ 1.3279, -1.3252],\n",
      "        [ 3.1084, -3.4759],\n",
      "        [ 3.0109, -3.7794]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.8608, device='cuda:0'), tensor([[-2.0915,  2.5495],\n",
      "        [-3.5149,  3.7602],\n",
      "        [ 2.5115, -2.7186],\n",
      "        [-2.8945,  3.7415],\n",
      "        [-3.2316,  3.7524],\n",
      "        [-2.6979,  3.3955],\n",
      "        [ 2.5995, -3.6311],\n",
      "        [-1.3142,  2.2454]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.8460, device='cuda:0'), tensor([[-2.9983,  3.7452],\n",
      "        [-1.7957,  2.5740],\n",
      "        [ 2.4615, -3.1673],\n",
      "        [ 2.7161, -3.4741],\n",
      "        [ 3.4272, -3.9127],\n",
      "        [-2.9701,  3.6554],\n",
      "        [-3.3706,  3.8484],\n",
      "        [-3.0076,  3.1501]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.6933, device='cuda:0'), tensor([[-3.3049,  3.7724],\n",
      "        [-3.3048,  3.8897],\n",
      "        [-2.9271,  3.3194],\n",
      "        [-2.9292,  3.4826],\n",
      "        [-2.9316,  3.3008],\n",
      "        [-3.4131,  3.8748],\n",
      "        [ 2.6754, -3.5841],\n",
      "        [-2.5892,  3.4607]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(1.7585, device='cuda:0'), tensor([[-3.3086,  3.6329],\n",
      "        [-3.3886,  3.7253],\n",
      "        [ 2.9441, -3.6939],\n",
      "        [-2.9690,  3.6749],\n",
      "        [-3.3223,  3.8386],\n",
      "        [-3.3039,  3.8811],\n",
      "        [-3.1148,  4.0035],\n",
      "        [ 3.0597, -3.5954]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(3.9864, device='cuda:0'), tensor([[ 2.6872, -3.0974],\n",
      "        [-3.5301,  3.8125],\n",
      "        [-1.1083,  1.7335],\n",
      "        [-3.5301,  3.8125],\n",
      "        [-3.1083,  3.6758],\n",
      "        [-3.3916,  3.8856],\n",
      "        [-3.1911,  3.7667],\n",
      "        [ 0.3920, -0.9174]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.9425, device='cuda:0'), tensor([[-3.4187,  3.6976],\n",
      "        [-3.4614,  3.6661],\n",
      "        [-3.5537,  3.7869],\n",
      "        [ 2.9577, -3.1371],\n",
      "        [-0.8353,  1.5392],\n",
      "        [-2.1471,  2.9170],\n",
      "        [-3.4319,  3.8033],\n",
      "        [-3.1277,  3.7919]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.5488, device='cuda:0'), tensor([[-3.2533,  3.7941],\n",
      "        [-3.0930,  3.8895],\n",
      "        [ 1.0713, -2.0373],\n",
      "        [-3.2741,  4.0037],\n",
      "        [ 2.9901, -3.8683],\n",
      "        [-2.9664,  3.7794],\n",
      "        [-3.3824,  3.7538],\n",
      "        [-2.8570,  3.3638]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.3260, device='cuda:0'), tensor([[-3.0381,  3.6909],\n",
      "        [-3.4257,  3.9335],\n",
      "        [-3.2741,  3.8902],\n",
      "        [ 3.2570, -3.7357],\n",
      "        [-3.0383,  3.6028],\n",
      "        [ 2.9203, -3.6841],\n",
      "        [-3.0025,  3.2274],\n",
      "        [-1.9433,  3.0611]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.7808, device='cuda:0'), tensor([[-3.1490,  3.5649],\n",
      "        [-3.1697,  3.8358],\n",
      "        [ 3.2281, -3.8233],\n",
      "        [-3.2888,  3.8840],\n",
      "        [-3.2800,  3.7663],\n",
      "        [ 1.5783, -2.3790],\n",
      "        [ 2.9400, -3.0690],\n",
      "        [-3.3966,  3.6943]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.7717, device='cuda:0'), tensor([[-2.7362,  3.4181],\n",
      "        [ 3.5804, -3.8854],\n",
      "        [-3.0968,  3.7621],\n",
      "        [-3.3290,  3.6585],\n",
      "        [ 3.2985, -3.8868],\n",
      "        [ 2.3344, -2.4446],\n",
      "        [-3.1607,  3.7634],\n",
      "        [ 2.3581, -3.0571]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.9375, device='cuda:0'), tensor([[-3.2957,  3.6729],\n",
      "        [ 2.3026, -2.7390],\n",
      "        [ 1.2597, -1.2151],\n",
      "        [ 2.8786, -3.2884],\n",
      "        [-3.5409,  3.8648],\n",
      "        [-2.6844,  3.5511],\n",
      "        [-3.3672,  3.7336],\n",
      "        [-3.3218,  3.8811]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.0022, device='cuda:0'), tensor([[-3.3803,  3.7571],\n",
      "        [ 2.6454, -3.0626],\n",
      "        [-3.2925,  3.9349],\n",
      "        [ 3.1129, -3.4585],\n",
      "        [ 3.1529, -3.8105],\n",
      "        [-3.1699,  3.7168],\n",
      "        [ 2.2059, -2.6098],\n",
      "        [-2.9891,  3.6112]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.5868, device='cuda:0'), tensor([[-3.2232,  3.9678],\n",
      "        [ 3.0805, -3.5458],\n",
      "        [-2.8081,  3.7466],\n",
      "        [-2.9550,  3.7608],\n",
      "        [ 0.7663, -0.6128],\n",
      "        [-2.8416,  3.7052],\n",
      "        [-3.0821,  3.7999],\n",
      "        [ 2.8583, -3.8659]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.7001, device='cuda:0'), tensor([[-3.4201,  3.7614],\n",
      "        [-3.2786,  3.8155],\n",
      "        [-2.9911,  3.5086],\n",
      "        [-3.1117,  3.5514],\n",
      "        [-3.3469,  3.8119],\n",
      "        [-3.4739,  3.7527],\n",
      "        [-3.5208,  3.8765],\n",
      "        [-3.2520,  3.7742]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.3788, device='cuda:0'), tensor([[-2.5574,  2.8876],\n",
      "        [ 2.8937, -3.5399],\n",
      "        [-3.2179,  3.8104],\n",
      "        [-2.9343,  3.7334],\n",
      "        [-3.2559,  3.8734],\n",
      "        [-0.7610,  1.5354],\n",
      "        [-3.2928,  3.8977],\n",
      "        [-0.0967, -0.2300]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.9009, device='cuda:0'), tensor([[ 2.3110, -2.6216],\n",
      "        [-3.1149,  3.6575],\n",
      "        [ 3.1013, -3.9432],\n",
      "        [-2.3590,  3.1421],\n",
      "        [-3.3005,  3.8662],\n",
      "        [ 1.8461, -1.8618],\n",
      "        [-3.0893,  3.8475],\n",
      "        [-3.3685,  3.7764]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(3.8504, device='cuda:0'), tensor([[-3.3126,  3.9822],\n",
      "        [-3.2763,  3.8421],\n",
      "        [-3.2534,  3.6671],\n",
      "        [-1.7532,  1.9768],\n",
      "        [-2.1600,  2.9112],\n",
      "        [-0.5020, -0.4791],\n",
      "        [-3.1522,  3.9099],\n",
      "        [-3.1394,  3.7670]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.4240, device='cuda:0'), tensor([[-3.1570,  3.6110],\n",
      "        [-3.3374,  3.7546],\n",
      "        [-3.4038,  3.6936],\n",
      "        [-3.3890,  3.7224],\n",
      "        [-3.4103,  3.7237],\n",
      "        [-0.3210,  0.9415],\n",
      "        [-3.4580,  3.8149],\n",
      "        [-1.3462,  1.7469]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.0547, device='cuda:0'), tensor([[-3.2580,  3.7760],\n",
      "        [-0.9235,  0.6632],\n",
      "        [-2.9477,  3.4353],\n",
      "        [-3.3858,  3.7139],\n",
      "        [ 3.0273, -3.3026],\n",
      "        [-3.2101,  3.9193],\n",
      "        [-2.7907,  3.8661],\n",
      "        [-3.3065,  3.8536]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.6076, device='cuda:0'), tensor([[-3.1419,  3.6266],\n",
      "        [ 2.6728, -3.3261],\n",
      "        [-3.0989,  3.8450],\n",
      "        [-3.4644,  3.7429],\n",
      "        [-3.2869,  3.8125],\n",
      "        [-3.1552,  3.8047],\n",
      "        [-2.8069,  3.5378],\n",
      "        [-3.3792,  3.7431]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(3.5127, device='cuda:0'), tensor([[-3.0406,  3.6674],\n",
      "        [-3.2241,  3.9735],\n",
      "        [-3.3665,  3.8365],\n",
      "        [-3.5516,  3.8148],\n",
      "        [-3.1611,  3.9106],\n",
      "        [-3.4909,  3.7706],\n",
      "        [-2.7529,  3.7002],\n",
      "        [-3.3859,  3.8504]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.7904, device='cuda:0'), tensor([[-3.2477,  3.9148],\n",
      "        [ 3.1023, -3.6411],\n",
      "        [ 3.0393, -3.3638],\n",
      "        [-3.3585,  3.7849],\n",
      "        [ 2.9858, -3.4977],\n",
      "        [-3.4438,  3.8311],\n",
      "        [-3.3321,  3.8204],\n",
      "        [-3.2625,  3.8578]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.7713, device='cuda:0'), tensor([[ 0.7326, -1.2222],\n",
      "        [-2.6454,  3.3023],\n",
      "        [-2.9906,  3.6106],\n",
      "        [ 2.2829, -2.2391],\n",
      "        [-3.3589,  3.7705],\n",
      "        [-2.9878,  3.5250],\n",
      "        [ 1.3236, -1.2576],\n",
      "        [-3.4417,  3.8292]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.8505, device='cuda:0'), tensor([[-3.2008,  3.6026],\n",
      "        [-3.3346,  3.7401],\n",
      "        [ 2.6559, -3.0229],\n",
      "        [-1.9727,  2.1050],\n",
      "        [-3.4468,  3.9061],\n",
      "        [-3.1705,  3.6077],\n",
      "        [-3.5297,  3.7550],\n",
      "        [-3.0859,  3.6779]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(3.3185, device='cuda:0'), tensor([[-3.1317,  3.8672],\n",
      "        [-1.8314,  2.8784],\n",
      "        [-3.0884,  3.8365],\n",
      "        [ 1.0595, -1.5822],\n",
      "        [-2.5621,  3.2833],\n",
      "        [-3.3919,  3.9807],\n",
      "        [-3.4991,  3.8237],\n",
      "        [-1.1568,  1.6207]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.5714, device='cuda:0'), tensor([[-0.3372, -0.1787],\n",
      "        [ 3.0847, -3.4960],\n",
      "        [-3.1559,  3.7233],\n",
      "        [-3.4556,  3.7338],\n",
      "        [-3.3956,  3.7916],\n",
      "        [-1.3269,  1.7034],\n",
      "        [-3.5600,  3.8349],\n",
      "        [-1.4859,  2.2343]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.6291, device='cuda:0'), tensor([[ 2.7240, -3.5408],\n",
      "        [-3.2867,  3.7444],\n",
      "        [-3.1792,  3.7785],\n",
      "        [-3.3851,  3.7780],\n",
      "        [-3.2030,  3.7697],\n",
      "        [-3.1215,  3.6032],\n",
      "        [ 1.0294, -0.5950],\n",
      "        [-3.3738,  3.8525]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(2.5589, device='cuda:0'), tensor([[-3.2118,  3.7951],\n",
      "        [ 1.5980, -1.6989],\n",
      "        [-3.2902,  3.8692],\n",
      "        [-3.0789,  3.7672],\n",
      "        [-3.4017,  3.6863],\n",
      "        [-3.2469,  3.9050],\n",
      "        [-3.3659,  3.8286],\n",
      "        [-1.2708,  1.4440]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.2782, device='cuda:0'), tensor([[-3.0447,  3.6214],\n",
      "        [-3.3797,  3.8160],\n",
      "        [ 3.0128, -3.5035],\n",
      "        [-1.0581,  2.4097],\n",
      "        [-3.3651,  3.7992],\n",
      "        [ 3.4844, -3.7189],\n",
      "        [-3.5239,  3.9353],\n",
      "        [-1.1850,  1.0899]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.8203, device='cuda:0'), tensor([[-3.0236,  3.5760],\n",
      "        [ 3.1243, -3.9664],\n",
      "        [ 0.6350,  0.2505],\n",
      "        [-3.4094,  4.0359],\n",
      "        [-3.0086,  3.6190],\n",
      "        [-3.2983,  3.7518],\n",
      "        [-3.3893,  3.6877],\n",
      "        [ 2.4171, -3.3808]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.8815, device='cuda:0'), tensor([[-2.1273,  2.8130],\n",
      "        [-3.2411,  3.8118],\n",
      "        [-3.2723,  3.9517],\n",
      "        [-2.3501,  2.9088],\n",
      "        [ 3.3812, -3.6530],\n",
      "        [-3.2242,  3.7611],\n",
      "        [-3.1740,  3.4927],\n",
      "        [-3.2226,  3.8076]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(0.6296, device='cuda:0'), tensor([[-2.8850,  3.4686],\n",
      "        [-2.1795,  2.8422],\n",
      "        [-2.9459,  3.5786],\n",
      "        [-3.0305,  3.3563],\n",
      "        [-3.4134,  3.9073],\n",
      "        [-3.3940,  3.6788],\n",
      "        [-3.3318,  3.7704],\n",
      "        [ 2.8988, -3.6216]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.7137, device='cuda:0'), tensor([[-3.3770,  3.8340],\n",
      "        [-1.4098,  1.8538],\n",
      "        [-2.0040,  2.8663],\n",
      "        [ 2.4588, -2.2879],\n",
      "        [ 2.7775, -2.7581],\n",
      "        [ 2.9084, -3.5446],\n",
      "        [-2.8852,  3.4171],\n",
      "        [-3.5157,  3.7403]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(3.3779, device='cuda:0'), tensor([[-2.7684,  3.1070],\n",
      "        [-3.1110,  3.6904],\n",
      "        [-3.1597,  3.7784],\n",
      "        [-3.1874,  3.8191],\n",
      "        [ 0.2236,  0.6749],\n",
      "        [ 2.9986, -3.7114],\n",
      "        [-2.4557,  2.9069],\n",
      "        [-3.0973,  3.8675]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.3927, device='cuda:0'), tensor([[ 3.1154, -3.8309],\n",
      "        [-2.0927,  2.4204],\n",
      "        [-3.1087,  3.7307],\n",
      "        [ 3.1131, -3.5316],\n",
      "        [-3.0932,  3.4961],\n",
      "        [ 2.8118, -3.7957],\n",
      "        [-2.6170,  3.0937],\n",
      "        [-3.2635,  3.6661]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.8750, device='cuda:0'), tensor([[ 0.0775,  0.3420],\n",
      "        [-3.2165,  3.6587],\n",
      "        [-3.3179,  3.7798],\n",
      "        [ 0.9132, -0.6653],\n",
      "        [-3.2861,  3.7050],\n",
      "        [ 2.9585, -3.6783],\n",
      "        [-3.5348,  3.7110],\n",
      "        [-3.3834,  3.7832]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.6838, device='cuda:0'), tensor([[-3.3642,  3.7136],\n",
      "        [-3.1838,  3.8252],\n",
      "        [-3.2278,  3.8436],\n",
      "        [ 2.8454, -3.6960],\n",
      "        [-2.7548,  3.5733],\n",
      "        [-3.1787,  3.7648],\n",
      "        [ 3.1472, -3.7779],\n",
      "        [-3.1488,  3.9852]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(1.6983, device='cuda:0'), tensor([[-2.6829,  3.3434],\n",
      "        [-2.8152,  3.8567],\n",
      "        [ 2.9262, -3.4531],\n",
      "        [-3.0698,  3.7224],\n",
      "        [ 1.0418, -1.0861],\n",
      "        [-3.0156,  3.5189],\n",
      "        [-3.3914,  3.7744],\n",
      "        [ 3.2223, -3.8039]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "(tensor(2.5112, device='cuda:0'), tensor([[-3.0401,  3.4924],\n",
      "        [-3.3333,  3.8969],\n",
      "        [-3.2525,  3.8733],\n",
      "        [-2.8650,  3.4525],\n",
      "        [ 2.4638, -2.0502],\n",
      "        [-2.7830,  3.5938],\n",
      "        [-3.4455,  3.7924],\n",
      "        [ 1.3515, -0.9460]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Eval results  *****\n",
      "INFO:__main__:  fn = 9\n",
      "INFO:__main__:  fp = 183\n",
      "INFO:__main__:  mcc = 0.5075483675930825\n",
      "INFO:__main__:  tn = 155\n",
      "INFO:__main__:  tp = 340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(2.0542, device='cuda:0'), tensor([[-3.2794,  3.7581],\n",
      "        [-3.1261,  3.7981],\n",
      "        [-3.2962,  3.8588],\n",
      "        [-3.1848,  3.8383],\n",
      "        [-2.9090,  3.5642],\n",
      "        [-3.4318,  3.7834],\n",
      "        [-2.5337,  3.1348]], device='cuda:0'), (None, None, None, None, None, None, None, None, None, None, None, None))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "if args['do_eval']:\n",
    "    checkpoints = [args['output_dir']]\n",
    "    if args['eval_all_checkpoints']:\n",
    "        checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args['output_dir'] + '/**/' + WEIGHTS_NAME, recursive=True)))\n",
    "        logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
    "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "    for checkpoint in checkpoints:\n",
    "        global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n",
    "        print(\"global_step\", global_step)\n",
    "        model = model_class.from_pretrained(checkpoint)\n",
    "        model.to(device)\n",
    "        result, wrong_preds = evaluate(model, tokenizer, prefix=global_step)\n",
    "        result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())\n",
    "        results.update(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fn_': 31, 'fp_': 29, 'mcc_': 0.42715677418452497, 'tn_': 54, 'tp_': 109}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7309417040358744"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = (results['tn_'] + results['tp_'])/(results['fn_'] + results['fp_'] + results['tn_'] + results['tp_'])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['fn_'] + results['fp_'] + results['tn_'] + results['tp_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7898550724637681"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = results['tp_']/(results['tp_'] + results['fp_'])\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7785714285714286"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = results['tp_']/(results['tp_']+results['fn_'])\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7841726618705036"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list = [2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = [0.6780185758513931, 0.7027863777089783, 0.7120743034055728, 0.70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f446648c8d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f446729a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, acc_list, linewidth=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_epoch_list = [2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_acc_list = [0.718266253869969, 0.7275541795665634, 0.739938080495356, 0.6965944272445821]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
